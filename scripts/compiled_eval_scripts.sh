accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=meta-llama/Llama-3.2-1B,     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/a76e08be-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/98a58ccc-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/5b438282-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/ae906530-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/f90d880c-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/4ae1e101-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/143e8cdc-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/2d0810f7-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/59bb6bcb-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/8afe6bac-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/a44a3a50-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
accelerate launch --num_processes 8 -m lm_eval     --model_args pretrained=output/199a1ed2-Llama-3.2-1B-SFT-10/final_model,tokenizer=/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-genqa-math-empty-start-10     --gen_kwargs do_sample=True,temperature=0.7,top_p=3     --tasks minerva_math     --batch_size auto     --output_path ./eval_results/results_10
