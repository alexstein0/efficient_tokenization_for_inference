{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = \"/cmlscratch/astein0/efficient_tokenization_for_inference/output/full_patching/0a90e719-Llama-3.2-3B-mixed-100/final_model\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer_path = \"/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-magpie_pro_300k_filtered-math-empty-start-100\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|          | 1.92M/4.93G [00:00<04:28, 18.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|          | 6.34M/4.93G [00:00<02:27, 33.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|          | 16.0M/4.93G [00:00<02:12, 37.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|          | 25.7M/4.93G [00:00<01:55, 42.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|          | 41.2M/4.93G [00:00<01:41, 48.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|          | 47.5M/4.93G [00:01<01:33, 52.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|          | 60.0M/4.93G [00:01<01:43, 46.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 73.1M/4.93G [00:01<01:43, 46.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 80.0M/4.93G [00:01<01:59, 40.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 89.7M/4.93G [00:02<01:33, 52.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 106M/4.93G [00:02<01:28, 54.3MB/s] \n",
      "\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 112M/4.93G [00:02<02:07, 37.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 130M/4.93G [00:02<01:48, 44.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 147M/4.93G [00:03<01:40, 47.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 165M/4.93G [00:03<01:36, 49.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 190M/4.93G [00:03<01:10, 67.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 198M/4.93G [00:04<01:21, 57.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 216M/4.93G [00:04<01:25, 55.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 224M/4.93G [00:04<01:37, 48.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 243M/4.93G [00:04<01:27, 53.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 262M/4.93G [00:05<01:26, 54.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 285M/4.93G [00:05<01:19, 58.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 293M/4.93G [00:05<01:26, 53.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 304M/4.93G [00:06<01:36, 48.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 328M/4.93G [00:06<01:22, 55.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 336M/4.93G [00:06<01:25, 53.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 352M/4.93G [00:06<01:22, 55.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 368M/4.93G [00:07<01:22, 55.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 384M/4.93G [00:07<01:24, 54.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 400M/4.93G [00:07<01:26, 52.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 416M/4.93G [00:08<01:25, 52.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 432M/4.93G [00:08<01:25, 52.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 448M/4.93G [00:08<01:19, 56.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 464M/4.93G [00:08<01:15, 59.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  10%|█         | 496M/4.93G [00:09<01:00, 73.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  10%|█         | 505M/4.93G [00:09<01:08, 64.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  10%|█         | 512M/4.93G [00:09<01:16, 57.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  11%|█         | 528M/4.93G [00:09<01:14, 58.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  11%|█         | 544M/4.93G [00:10<01:08, 63.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 576M/4.93G [00:10<01:11, 60.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 592M/4.93G [00:10<01:14, 58.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 608M/4.93G [00:11<01:09, 62.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 640M/4.93G [00:11<01:10, 60.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 656M/4.93G [00:12<01:11, 60.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|█▎        | 672M/4.93G [00:12<01:08, 61.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 688M/4.93G [00:12<01:08, 62.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 704M/4.93G [00:12<01:12, 58.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 752M/4.93G [00:13<01:07, 62.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 768M/4.93G [00:13<01:07, 61.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 784M/4.93G [00:14<01:05, 63.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 800M/4.93G [00:14<01:05, 63.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 830M/4.93G [00:16<02:46, 24.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 837M/4.93G [00:16<02:40, 25.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 864M/4.93G [00:17<01:53, 35.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 896M/4.93G [00:17<01:33, 43.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 960M/4.93G [00:19<01:10, 56.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 976M/4.93G [00:19<01:09, 56.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  20%|██        | 992M/4.93G [00:19<01:11, 55.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  20%|██        | 1.01G/4.93G [00:19<01:05, 59.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.02G/4.93G [00:20<01:05, 59.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.10G/4.93G [00:21<01:03, 60.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.12G/4.93G [00:25<05:15, 12.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.13G/4.93G [00:25<03:59, 15.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.14G/4.93G [00:25<03:41, 17.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.15G/4.93G [00:25<03:01, 20.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██▎       | 1.17G/4.93G [00:26<02:13, 28.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.18G/4.93G [00:26<01:51, 33.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.20G/4.93G [00:26<01:35, 39.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.22G/4.93G [00:26<01:25, 43.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.23G/4.93G [00:27<01:17, 47.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.26G/4.93G [00:27<00:55, 65.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.27G/4.93G [00:28<02:06, 29.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|██▋       | 1.30G/4.93G [00:28<01:22, 44.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|██▋       | 1.30G/4.93G [00:28<01:23, 43.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.31G/4.93G [00:29<01:31, 39.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.33G/4.93G [00:29<01:15, 47.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.36G/4.93G [00:29<01:00, 59.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.38G/4.93G [00:30<01:00, 59.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.39G/4.93G [00:30<00:59, 59.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|██▊       | 1.41G/4.93G [00:30<01:01, 57.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.42G/4.93G [00:30<01:01, 56.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.44G/4.93G [00:31<01:00, 57.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|██▉       | 1.46G/4.93G [00:31<00:58, 59.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|██▉       | 1.47G/4.93G [00:32<01:23, 41.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.49G/4.93G [00:32<01:16, 45.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.50G/4.93G [00:32<01:06, 51.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.52G/4.93G [00:32<01:01, 55.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.54G/4.93G [00:33<01:01, 54.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|███▏      | 1.55G/4.93G [00:33<01:01, 55.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.57G/4.93G [00:33<00:55, 60.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.58G/4.93G [00:33<00:57, 58.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.60G/4.93G [00:34<00:56, 59.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.62G/4.93G [00:34<00:56, 58.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.63G/4.93G [00:34<00:54, 60.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.65G/4.93G [00:34<00:52, 62.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|███▎      | 1.66G/4.93G [00:35<00:52, 62.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|███▍      | 1.68G/4.93G [00:35<01:00, 53.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|███▍      | 1.70G/4.93G [00:35<00:59, 54.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.73G/4.93G [00:36<00:55, 57.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.74G/4.93G [00:36<00:54, 58.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.76G/4.93G [00:36<00:53, 59.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.78G/4.93G [00:37<00:52, 60.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  36%|███▋      | 1.79G/4.93G [00:37<00:54, 57.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.81G/4.93G [00:37<00:54, 57.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.82G/4.93G [00:38<00:51, 59.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.84G/4.93G [00:38<00:47, 64.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.86G/4.93G [00:38<00:46, 66.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.87G/4.93G [00:38<00:45, 66.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.89G/4.93G [00:38<00:47, 64.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|███▊      | 1.90G/4.93G [00:39<00:46, 65.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.94G/4.93G [00:39<00:47, 63.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|███▉      | 1.95G/4.93G [00:40<00:46, 63.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|███▉      | 1.97G/4.93G [00:40<00:46, 63.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|████      | 1.98G/4.93G [00:40<00:44, 65.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.00G/4.93G [00:40<00:43, 68.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.02G/4.93G [00:40<00:46, 62.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.03G/4.93G [00:41<00:47, 60.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.13G/4.93G [00:42<00:45, 61.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.14G/4.93G [00:44<02:10, 21.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.16G/4.93G [00:45<01:46, 25.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.18G/4.93G [00:45<01:28, 31.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.21G/4.93G [00:45<01:04, 41.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.22G/4.93G [00:46<00:58, 46.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.24G/4.93G [00:46<01:01, 44.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.26G/4.93G [00:46<00:54, 49.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.27G/4.93G [00:47<00:48, 55.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|████▋     | 2.29G/4.93G [00:47<00:43, 61.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.30G/4.93G [00:47<00:42, 62.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.32G/4.93G [00:47<00:42, 61.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.35G/4.93G [00:48<00:43, 58.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.37G/4.93G [00:48<00:44, 58.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.38G/4.93G [00:48<00:45, 56.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|████▊     | 2.40G/4.93G [00:49<00:43, 58.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.42G/4.93G [00:49<00:44, 57.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.43G/4.93G [00:49<00:42, 59.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.45G/4.93G [00:49<00:41, 59.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.46G/4.93G [00:50<00:48, 50.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.48G/4.93G [00:50<00:45, 54.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.50G/4.93G [00:50<00:42, 56.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.51G/4.93G [00:51<00:43, 56.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.53G/4.93G [00:51<00:39, 60.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.54G/4.93G [00:51<00:41, 58.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.56G/4.93G [00:51<00:41, 57.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.59G/4.93G [00:52<00:37, 62.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.61G/4.93G [00:52<00:34, 66.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.62G/4.93G [00:52<00:36, 63.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  54%|█████▎    | 2.64G/4.93G [00:53<00:35, 64.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.67G/4.93G [00:53<00:32, 68.8MB/s]\n",
      "\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 2.92G/2.92G [00:53<00:00, 54.3MB/s]\n",
      "model-00001-of-00003.safetensors: 100%|██████████| 5.00G/5.00G [01:25<00:00, 58.8MB/s]\n",
      "model-00002-of-00003.safetensors: 100%|██████████| 4.93G/4.93G [01:37<00:00, 50.8MB/s]\n",
      "\n",
      "Upload 3 LFS files: 100%|██████████| 3/3 [01:37<00:00, 32.44s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Inferring the task automatically requires to check the hub with a model_id defined as a `str`. LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128356, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128356, bias=False)\n) is not a valid model_id.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# components.push_to_hub(\"tomg-group-umd/Efficient_inference_models-Testing\", private=True)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 9\u001b[0m mypipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m mypipeline\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtomg-group-umd/Efficient_inference_models-Testing\u001b[39m\u001b[38;5;124m\"\u001b[39m, private\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/eff-tok/lib/python3.10/site-packages/transformers/pipelines/__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    871\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferring the task automatically requires to check the hub with a model_id defined as a `str`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid model_id.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    873\u001b[0m         )\n\u001b[1;32m    874\u001b[0m     task \u001b[38;5;241m=\u001b[39m get_task(model, token)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Retrieve the task\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inferring the task automatically requires to check the hub with a model_id defined as a `str`. LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128356, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128356, bias=False)\n) is not a valid model_id."
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"tomg-group-umd/Efficient_inference_models-Testing\", private=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZER PUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|██████████| 17.3M/17.3M [00:00<00:00, 41.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tomg-group-umd/EIM-tokenizer-llama3.2-magpie-100/commit/968a29d0b24253d5ea305467a2b3a6b68e122a85', commit_message='Upload tokenizer', commit_description='', oid='968a29d0b24253d5ea305467a2b3a6b68e122a85', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tomg-group-umd/EIM-tokenizer-llama3.2-magpie-100', endpoint='https://huggingface.co', repo_type='model', repo_id='tomg-group-umd/EIM-tokenizer-llama3.2-magpie-100'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_path = \"/cmlscratch/astein0/efficient_tokenization_for_inference/tokenizers/Llama-3.2-tokenizer-magpie_pro_300k_filtered-math-empty-start-1000\"\n",
    "push_path = \"tomg-group-umd/EIM-tokenizer-llama3.2-magpie-1000\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "tokenizer.push_to_hub(push_path, private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = \"tomg-group-umd/EIM-tokenizer-llama3.2-magpie-1000\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'loss_mask', 'labels', 'task_type', 'num_tokens'],\n",
       "    num_rows: 300000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "ds_name = \"magpie-default-tokenized_1000\"\n",
    "ds_dir = \"datasets\"\n",
    "\n",
    "ds_path = os.path.join(ds_dir, ds_name)\n",
    "\n",
    "ds = load_from_disk(ds_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:08<00:00,  4.50ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:08<00:00,  4.74ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:07<00:00,  4.89ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:07<00:00,  5.00ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:08<00:00,  4.55ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:08<00:00,  4.60ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:08<00:00,  4.63ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 38/38 [00:07<00:00,  5.14ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 8/8 [01:24<00:00, 10.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tomg-group-umd/EIM-dataset-llama3.2-magpie-1000/commit/e578d95f11b8ea00c8991b216e7dada36f9d5334', commit_message='Upload dataset', commit_description='', oid='e578d95f11b8ea00c8991b216e7dada36f9d5334', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/tomg-group-umd/EIM-dataset-llama3.2-magpie-1000', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tomg-group-umd/EIM-dataset-llama3.2-magpie-1000'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"tomg-group-umd/EIM-dataset-llama3.2-magpie-1000\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff-tok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
